#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
  # Loop header
  # xorq %rax,%rax    # count = 0;
  iaddq $-9, %rdx
  jge K_Loop
  jmp Remainder

K_Loop:
  mrmovq (%rdi), %r8
  mrmovq 0x08(%rdi), %r9
  andq %r8, %r8
  rmmovq %r8, (%rsi)  
  jle Npos1
  iaddq $1, %rax
Npos1:
  rmmovq %r9, 0x08(%rsi)
  andq %r9, %r9    
  mrmovq 0x10(%rdi), %r8
  jle Npos2
  iaddq $1, %rax
Npos2:  
  rmmovq %r8, 0x10(%rsi)
  andq %r8, %r8
  mrmovq 0x18(%rdi), %r8
  jle Npos3    
  iaddq $1, %rax
Npos3:
  rmmovq %r8, 0x18(%rsi)
  andq %r8, %r8
  mrmovq 0x20(%rdi), %r8
  jle Npos4  
  iaddq $1, %rax
Npos4:
  rmmovq %r8, 0x20(%rsi)
  andq %r8, %r8
  mrmovq 0x28(%rdi), %r8
  jle Npos5
  iaddq $1, %rax
Npos5:
  rmmovq %r8, 0x28(%rsi)
  andq %r8, %r8
  mrmovq 0x30(%rdi), %r8
  jle Npos6
  iaddq $1, %rax
Npos6:
  rmmovq %r8, 0x30(%rsi)
  andq %r8, %r8
  mrmovq 0x38(%rdi), %r8
  jle Npos7
  iaddq $1, %rax
Npos7:
  rmmovq %r8, 0x38(%rsi)
  andq %r8, %r8  
  mrmovq 0x40(%rdi), %r8
  jle Npos8
  iaddq $1, %rax
Npos8:
  rmmovq %r8, 0x40(%rsi)
  andq %r8, %r8  
  jle Npos9
  iaddq $1, %rax
Npos9:
  iaddq $0x48, %rdi  
  iaddq $0x48, %rsi
  iaddq $-9, %rdx
  jge K_Loop

Remainder:
  iaddq $5, %rdx
  mrmovq (%rdi), %r8
  jl Remainder_0_3
  rmmovq %r8, (%rsi)
  jg Remainder_5_8
  jmp Remainder_4

Remainder_0_3:
  iaddq $2, %rdx
  jl Remainder_0_1
  rmmovq %r8, (%rsi)
  je Remainder_2
  jg Remainder_3

Remainder_0_1:
  iaddq $1, %rdx
  je Remainder_1
  ret

Remainder_5_8:
  iaddq $-2, %rdx
  jg Remainder_7_8
  jl Remainder_5
  je Remainder_6

Remainder_7_8:
  iaddq $-1, %rdx
  je Remainder_7

Remainder_8:
  andq %r8, %r8
  mrmovq 56(%rdi), %r8
  jle Remainder_Nop8
  iaddq $1, %rax
Remainder_Nop8:
  rmmovq %r8, 56(%rsi)

Remainder_7:
  andq %r8, %r8
  mrmovq 48(%rdi), %r8
  jle Remainder_Nop7
  iaddq $1, %rax
Remainder_Nop7:
  rmmovq %r8, 48(%rsi)

Remainder_6:
  andq %r8, %r8
  mrmovq 40(%rdi), %r8
  jle Remainder_Nop6
  iaddq $1, %rax
Remainder_Nop6:
  rmmovq %r8, 40(%rsi)

Remainder_5:
  andq %r8, %r8
  mrmovq 32(%rdi), %r8
  jle Remainder_Nop5
  iaddq $1, %rax
Remainder_Nop5:
  rmmovq %r8, 32(%rsi)

Remainder_4:
  andq %r8, %r8
  mrmovq 24(%rdi), %r8
  jle Remainder_Nop4
  iaddq $1, %rax
Remainder_Nop4:
  rmmovq %r8, 24(%rsi)

Remainder_3:
  andq %r8, %r8
  mrmovq 16(%rdi), %r8
  jle Remainder_Nop3
  iaddq $1, %rax
Remainder_Nop3:
  rmmovq %r8, 16(%rsi)

Remainder_2:
  andq %r8, %r8
  mrmovq 8(%rdi), %r8
  jle Remainder_Nop2
  iaddq $1, %rax
Remainder_Nop2:
  rmmovq %r8, 8(%rsi)
  andq %r8, %r8
  jle Done
  iaddq $1, %rax
  ret

Remainder_1:
  rmmovq %r8, (%rsi)
  andq %r8, %r8
  jle Done
  iaddq $1, %rax
  ret

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
  ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad -2
	.quad -3
	.quad 4
	.quad 5
	.quad 6
	.quad 7
	.quad -8
	.quad -9
	.quad -10
	.quad -11
	.quad 12
	.quad -13
	.quad 14
	.quad 15
	.quad -16
	.quad -17
	.quad -18
	.quad 19
	.quad 20
	.quad 21
	.quad -22
	.quad -23
	.quad 24
	.quad -25
	.quad 26
	.quad 27
	.quad -28
	.quad 29
	.quad -30
	.quad 31
	.quad -32
	.quad 33
	.quad -34
	.quad 35
	.quad -36
	.quad -37
	.quad 38
	.quad 39
	.quad 40
	.quad -41
	.quad 42
	.quad 43
	.quad 44
	.quad 45
	.quad 46
	.quad 47
	.quad -48
	.quad 49
	.quad -50
	.quad 51
	.quad 52
	.quad -53
	.quad -54
	.quad 55
	.quad -56
	.quad -57
	.quad -58
	.quad -59
	.quad -60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
